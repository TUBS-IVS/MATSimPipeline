{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This isn't part of the automated pipeline, but needed to get input data ready. It may vary depending on the data source.\n",
   "id": "8b39b3de1678aa70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extract and merge Gitter data",
   "id": "fb7a3483bb11db0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import zipfile\n",
    "from doctest import debug\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# To use for all three data levels, find and replace '100m' with '1km' or '10km' as needed.\n",
    "\n",
    "def extract_zip_files(zip_folder, extract_to):\n",
    "    \"\"\"Extracts all zip files in the given folder.\"\"\"\n",
    "    zip_files = [f for f in os.listdir(zip_folder) if f.endswith(\".zip\")]\n",
    "    print(f\"Found {len(zip_files)} zip files.\")\n",
    "\n",
    "    extracted_files = []\n",
    "    for zip_file in zip_files:\n",
    "        zip_path = os.path.join(zip_folder, zip_file)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "            z.extractall(extract_to)\n",
    "            extracted_files.extend([os.path.join(extract_to, name) for name in z.namelist()])\n",
    "\n",
    "    print(f\"Extracted {len(extracted_files)} files.\")\n",
    "    return extracted_files\n",
    "\n",
    "\n",
    "def find_csv_files(files):\n",
    "    \"\"\"Finds CSV files that contain '1km-Gitter' in the name.\"\"\"\n",
    "    csv_files = [f for f in files if \"1km-Gitter\" in f and f.endswith(\".csv\")]\n",
    "    print(f\"Found {len(csv_files)} relevant CSV files.\")\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Removes special characters and replaces them with an empty string.\"\"\"\n",
    "    return re.sub(r'[^\\x20-\\x7E]', '', text)  # Keeps only printable ASCII characters\n",
    "\n",
    "\n",
    "def convert_numeric_columns(df):\n",
    "    \"\"\"Ensures numeric columns with comma decimals ('9,07') are properly converted to floats.\"\"\"\n",
    "    for col in df.columns:\n",
    "        # Only modify string columns\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].str.replace(',', '.', regex=False)  # Replace commas with dots for decimal conversion\n",
    "            df[col] = pd.to_numeric(df[col], errors='ignore')  # Convert to float, set invalid entries to NaN\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_csv_with_encoding(file):\n",
    "    \"\"\"Reads CSV with UTF-8 first, falls back to ISO-8859-1 if needed.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='utf-8', dtype=str, sep=';', encoding_errors='replace')\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Warning: UTF-8 failed for {file}, trying ISO-8859-1.\")\n",
    "        df = pd.read_csv(file, encoding='ISO-8859-1', dtype=str, sep=';', encoding_errors='replace')\n",
    "\n",
    "    # Apply text cleaning to all string values\n",
    "    df = df.applymap(lambda x: clean_text(x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Convert numeric values from '9,07' to 9.07\n",
    "    df = convert_numeric_columns(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_and_merge_csv(files):\n",
    "    \"\"\"Reads, processes, and merges CSV files on 'GITTER_ID_1km'.\"\"\"\n",
    "    merged_df = None\n",
    "\n",
    "    for file in files:\n",
    "        print(f\"Processing: {file}\")\n",
    "        df = read_csv_with_encoding(file)\n",
    "\n",
    "        # Standardize column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Drop unwanted columns if they exist\n",
    "        df.drop(columns=[col for col in ['x_mp_1km', 'y_mp_1km'] if col in df.columns], inplace=True, errors='ignore')\n",
    "\n",
    "        if 'GITTER_ID_1km' not in df.columns:\n",
    "            print(f\"Warning: 'GITTER_ID_1km' not found in {file}. Available columns: {df.columns.tolist()}\")\n",
    "            continue\n",
    "\n",
    "        # Rename duplicate columns before merging\n",
    "        df = df.rename(columns={col: f\"{col}_{os.path.basename(file).split('.')[0]}\" for col in df.columns if\n",
    "                                col != 'GITTER_ID_1km'})\n",
    "\n",
    "        if merged_df is None:\n",
    "            merged_df = df\n",
    "        else:\n",
    "            merged_df = merged_df.merge(df, on='GITTER_ID_1km', how='outer', suffixes=(None, None))\n",
    "\n",
    "    print(\"Merging complete.\")\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# Define paths\n",
    "zip_folder = r\"C:\\Users\\petre\\Desktop\\Synpop\\Zensus\"\n",
    "extract_to = r\"C:\\Users\\petre\\Desktop\\Synpop\\Zensus\\Extrahiert\"\n",
    "output_file = \"merged_1km_gitter.csv\"\n",
    "output_excel = \"merged_1km_gitter.xlsx\"\n",
    "\n",
    "# Execution pipeline\n",
    "extracted_files = extract_zip_files(zip_folder, extract_to)\n",
    "csv_files = find_csv_files(extracted_files)\n",
    "merged_data = process_and_merge_csv(csv_files)\n",
    "\n",
    "# Save to CSV\n",
    "if merged_data is not None:\n",
    "    merged_data.to_csv(output_file, index=False)\n",
    "    print(f\"Saved merged file to {output_file}\")\n",
    "else:\n",
    "    print(\"No valid data to save.\")\n",
    "\n",
    "# # Save to Excel -> sheet to large\n",
    "# if merged_data is not None:\n",
    "#     merged_data.to_excel(output_excel, index=False)\n",
    "#     print(f\"Saved merged file to {output_excel}\")\n"
   ],
   "id": "848b4dfedc2f64ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Impute missing/inaccurate population values (just multiplication to fit the total -> very low values stay very low)",
   "id": "43e1e7892b405c0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T14:57:13.438749500Z",
     "start_time": "2025-03-18T14:30:50.356605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def normalize_id(gid, replace_digits):\n",
    "    match = re.search(r'(N\\d+)(E\\d+)', gid)\n",
    "    if match:\n",
    "        n_part, e_part = match.groups()\n",
    "        n_base = n_part[:-replace_digits] + '0' * replace_digits\n",
    "        e_base = e_part[:-replace_digits] + '0' * replace_digits\n",
    "        return n_base + e_base\n",
    "    return gid\n",
    "\n",
    "\n",
    "def smart_integerize(df, pop_cols):\n",
    "    for pop_col in pop_cols:\n",
    "        total_before = df[pop_col].sum()\n",
    "        df[pop_col] = df[pop_col].round().astype(int)\n",
    "        total_after = df[pop_col].sum()\n",
    "        diff = total_before - total_after\n",
    "        if diff != 0:\n",
    "            sorted_indices = df[pop_col].abs().sort_values(ascending=False).index[:abs(int(diff))]\n",
    "            df.loc[sorted_indices, pop_col] += int(diff / abs(diff))\n",
    "\n",
    "\n",
    "def adjust_population(lower_level_file, higher_level_file, replace_digits_lower, replace_digits_higher, id_col_lower,\n",
    "                      id_col_higher, pop_cols_lower, pop_cols_higher, output_file):\n",
    "    lower_df = pd.read_csv(lower_level_file)\n",
    "    higher_df = pd.read_csv(higher_level_file)\n",
    "\n",
    "    assert id_col_lower in lower_df.columns and all(\n",
    "        col in lower_df.columns for col in pop_cols_lower), \"Lower level dataset missing required columns.\"\n",
    "    assert id_col_higher in higher_df.columns and all(\n",
    "        col in higher_df.columns for col in pop_cols_higher), \"Higher level dataset missing required columns.\"\n",
    "\n",
    "    lower_df['GroupID'] = lower_df[id_col_lower].apply(lambda x: normalize_id(str(x), replace_digits_lower))\n",
    "    higher_df['GroupID'] = higher_df[id_col_higher].apply(lambda x: normalize_id(str(x), replace_digits_higher))\n",
    "\n",
    "    lower_grouped = lower_df.groupby('GroupID')[pop_cols_lower].sum().reset_index()\n",
    "    merged = lower_grouped.merge(higher_df[['GroupID'] + pop_cols_higher], on='GroupID', how='left')\n",
    "\n",
    "    for pop_lower, pop_higher in zip(pop_cols_lower, pop_cols_higher):\n",
    "        merged[pop_higher] = merged[pop_higher].fillna(merged[pop_lower])\n",
    "        merged[f'AdjustmentFactor_{pop_higher}'] = merged[pop_higher] / merged[pop_lower]\n",
    "        merged[f'AdjustmentFactor_{pop_higher}'].fillna(1.0, inplace=True)\n",
    "\n",
    "    lower_df = lower_df.merge(merged[['GroupID'] + [f'AdjustmentFactor_{col}' for col in pop_cols_higher]],\n",
    "                              on='GroupID', how='left')\n",
    "\n",
    "    for pop_lower, pop_higher in zip(pop_cols_lower, pop_cols_higher):\n",
    "        lower_df[f'Adjusted_{pop_lower}'] = lower_df[pop_lower] * lower_df[f'AdjustmentFactor_{pop_higher}']\n",
    "\n",
    "    # Set nans to 0\n",
    "    lower_df.fillna(0, inplace=True)\n",
    "    # This ensures total population, but within the cell, it may cause minor differences (since this is global)\n",
    "    smart_integerize(lower_df, [f'Adjusted_{col}' for col in pop_cols_lower])\n",
    "\n",
    "    save_csv = lower_df[[id_col_lower] + [f'Adjusted_{col}' for col in pop_cols_lower]]\n",
    "    # Remove the adjusted prefix in the col name\n",
    "    save_csv.columns = [col.replace('Adjusted_', '') for col in save_csv.columns]\n",
    "    save_csv.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Adjusted population data saved to {output_file}\")\n",
    "\n",
    "\n",
    "adjust_population(r\"C:\\Users\\petre\\Documents\\GitHub\\MATSimPipeline\\data\\syn_pop\\merged_1km_gitter.csv\",\n",
    "                  r\"C:\\Users\\petre\\Documents\\GitHub\\MATSimPipeline\\data\\syn_pop\\merged_10km_gitter.csv\",\n",
    "                  replace_digits_lower=4, replace_digits_higher=4,\n",
    "                  id_col_lower='GITTER_ID_1km', id_col_higher='GITTER_ID_10km',\n",
    "                  pop_cols_lower=['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter',\n",
    "                                  'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter'],\n",
    "                  pop_cols_higher=['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "                                   'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'],\n",
    "                  output_file=\"1adjusted_1km.csv\")\n",
    "\n",
    "adjust_population(r\"C:\\Users\\petre\\Documents\\GitHub\\MATSimPipeline\\data\\syn_pop\\merged_100m_gitter.csv\",\n",
    "                  \"1adjusted_1km.csv\", replace_digits_lower=3, replace_digits_higher=3,\n",
    "                  id_col_lower='GITTER_ID_100m', id_col_higher='GITTER_ID_1km',\n",
    "                  pop_cols_lower=['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_100m-Gitter',\n",
    "                                  'Insgesamt_Bevoelkerung_Zensus2022_Alter_5Altersklassen_100m-Gitter'],\n",
    "                  pop_cols_higher=['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter',\n",
    "                                   'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter'],\n",
    "                  output_file=\"1adjusted_100m.csv\")\n"
   ],
   "id": "5145bfb8aa44dc01",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_15232\\3029198941.py:24: DtypeWarning: Columns (27,34,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lower_df = pd.read_csv(lower_level_file)\n",
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_15232\\3029198941.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged[f'AdjustmentFactor_{pop_higher}'].fillna(1.0, inplace=True)\n",
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_15232\\3029198941.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged[f'AdjustmentFactor_{pop_higher}'].fillna(1.0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted population data saved to adjusted_100m.csv\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merge and do some cleanup",
   "id": "e4a47f583ed16c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T14:57:13.439746900Z",
     "start_time": "2025-03-18T15:12:56.507282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def merge_adjusted_with_original(original_file, adjusted_file, pop_cols, to_file):\n",
    "    original_df = pd.read_csv(original_file)\n",
    "    adjusted_df = pd.read_csv(adjusted_file)\n",
    "\n",
    "    for pop_col in pop_cols:\n",
    "        total_diff = adjusted_df[pop_col].sum() - original_df[pop_col].sum()\n",
    "        max_diff = (adjusted_df[pop_col] - original_df[pop_col]).abs().max()\n",
    "        print(f\"{pop_col} - Total Difference: {total_diff}, Max Difference per row: {max_diff}\")\n",
    "\n",
    "    for pop_col in pop_cols:\n",
    "        original_df[f'adjustment_diff_{pop_col}'] = adjusted_df[pop_col] - original_df[pop_col]\n",
    "        original_df[pop_col] = adjusted_df[pop_col]\n",
    "\n",
    "    if \"Insgesamt_Bevoelkerung_Zensus2022_Alter_5Altersklassen_100m-Gitter\" in original_df.columns:\n",
    "        original_df.rename(columns={\n",
    "            \"Insgesamt_Bevoelkerung_Zensus2022_Alter_5Altersklassen_100m-Gitter\": \"Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_100m-Gitter\"},\n",
    "            inplace=True)\n",
    "\n",
    "    original_df.to_csv(to_file, index=False)\n",
    "    print(f\"Merged data saved to {to_file}\")\n",
    "\n",
    "\n",
    "merge_adjusted_with_original(r\"C:\\Users\\petre\\Documents\\GitHub\\MATSimPipeline\\data\\syn_pop\\merged_1km_gitter.csv\",\n",
    "                             \"adjusted_1km.csv\", [\n",
    "                                 'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter',\n",
    "                                 'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter'\n",
    "                             ],\n",
    "                             \"2poptotal_adjusted_1km_gitter.csv\")\n",
    "\n",
    "merge_adjusted_with_original(r\"C:\\Users\\petre\\Documents\\GitHub\\MATSimPipeline\\data\\syn_pop\\merged_100m_gitter.csv\",\n",
    "                             \"adjusted_100m.csv\", [\n",
    "                                 'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_100m-Gitter',\n",
    "                                 'Insgesamt_Bevoelkerung_Zensus2022_Alter_5Altersklassen_100m-Gitter'\n",
    "                             ],\n",
    "                             \"2poptotal_adjusted_100m_gitter.csv\")"
   ],
   "id": "4d09697d64125125",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_15232\\967282453.py:4: DtypeWarning: Columns (34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_df = pd.read_csv(original_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter - Total Difference: 4921.0, Max Difference per row: 13.0\n",
      "Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter - Total Difference: 4921.0, Max Difference per row: 13.0\n",
      "Merged data saved to poptotal_adjusted_1km_gitter.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_15232\\967282453.py:4: DtypeWarning: Columns (27,34,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_df = pd.read_csv(original_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_100m-Gitter - Total Difference: 135944.0, Max Difference per row: 12.0\n",
      "Insgesamt_Bevoelkerung_Zensus2022_Alter_5Altersklassen_100m-Gitter - Total Difference: 135944.0, Max Difference per row: 12.0\n",
      "Merged data saved to poptotal_adjusted_100m_gitter.csv\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ensure the population totals match",
   "id": "8afe6c98690a1ac8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T14:57:13.439746900Z",
     "start_time": "2025-03-18T15:59:03.923805Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_15232\\2574285654.py:1: DtypeWarning: Columns (34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  compare1 = pd.read_csv(\"poptotal_adjusted_1km_gitter.csv\")\n",
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_15232\\2574285654.py:2: DtypeWarning: Columns (27,34,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  compare2 = pd.read_csv(\"poptotal_adjusted_100m_gitter.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 45,
   "source": [
    "compare1 = pd.read_csv(\"2poptotal_adjusted_1km_gitter.csv\")\n",
    "compare2 = pd.read_csv(\"2poptotal_adjusted_100m_gitter.csv\")\n",
    "diff = compare1[\"Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter\"] - compare1[\n",
    "    \"Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter\"]\n",
    "print(max(diff))\n",
    "diff = compare2[\"Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_100m-Gitter\"] - compare2[\n",
    "    \"Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_100m-Gitter\"]\n",
    "print(max(diff))"
   ],
   "id": "af1259e530fe4f20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Impute age distribution",
   "id": "d367910968dbfa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T14:57:13.440789500Z",
     "start_time": "2025-03-24T08:57:42.012571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add higher level IDs to 1km and 100m\n",
    "\n",
    "def normalize_id(gid, replace_digits):\n",
    "    match = re.search(r'(N\\d+)(E\\d+)', gid)\n",
    "    if match:\n",
    "        n_part, e_part = match.groups()\n",
    "        n_base = n_part[:-replace_digits] + '0' * replace_digits\n",
    "        e_base = e_part[:-replace_digits] + '0' * replace_digits\n",
    "        return n_base + e_base\n",
    "    return gid\n",
    "\n",
    "\n",
    "def add_higher_level_id(df, id_col, replace_digits, new_col_name):\n",
    "    df[new_col_name] = df[id_col].apply(lambda x: normalize_id(str(x), replace_digits))\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepend_id(df, id_col, prefix, new_col_name):\n",
    "    df[new_col_name] = prefix + df[id_col].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Add 10km ID to 1km\n",
    "one_km_df = pd.read_csv(\"2poptotal_adjusted_1km_gitter.csv\")\n",
    "one_km_df = add_higher_level_id(one_km_df, 'GITTER_ID_1km', 4, 'GITTER_ID_10km')\n",
    "one_km_df = prepend_id(one_km_df, 'GITTER_ID_10km', 'CRS3035RES10000m', 'GITTER_ID_10km')\n",
    "one_km_df.to_csv(\"3adjusted_1km_with_higher.csv\", index=False)\n",
    "\n",
    "# Add 1km ID to 100m\n",
    "hundred_m_df = pd.read_csv(\"2poptotal_adjusted_100m_gitter.csv\")\n",
    "hundred_m_df = add_higher_level_id(hundred_m_df, 'GITTER_ID_100m', 3, 'GITTER_ID_1km')\n",
    "hundred_m_df = prepend_id(hundred_m_df, 'GITTER_ID_1km', 'CRS3035RES1000m', 'GITTER_ID_1km')\n",
    "\n",
    "# Add 10km ID to 100m\n",
    "hundred_m_df = add_higher_level_id(hundred_m_df, 'GITTER_ID_100m', 4, 'GITTER_ID_10km')\n",
    "hundred_m_df = prepend_id(hundred_m_df, 'GITTER_ID_10km', 'CRS3035RES10000m', 'GITTER_ID_10km')\n",
    "hundred_m_df.to_csv(\"3adjusted_100m_with_higher.csv\", index=False)\n"
   ],
   "id": "f8bafa02c4a3c2a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_17900\\3198254823.py:21: DtypeWarning: Columns (34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  one_km_df = pd.read_csv(\"2poptotal_adjusted_1km_gitter.csv\")\n",
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_17900\\3198254823.py:27: DtypeWarning: Columns (27,34,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  hundred_m_df = pd.read_csv(\"2poptotal_adjusted_100m_gitter.csv\")\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T14:57:13.440789500Z",
     "start_time": "2025-03-24T10:20:49.145317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def smart_integerize(df, pop_cols):\n",
    "    for pop_col in pop_cols:\n",
    "        total_before = df[pop_col].sum()\n",
    "        df[pop_col] = df[pop_col].round().astype(int)\n",
    "        total_after = df[pop_col].sum()\n",
    "        diff = total_before - total_after\n",
    "        if diff != 0:\n",
    "            sorted_indices = df[pop_col].abs().sort_values(ascending=False).index[:abs(int(diff))]\n",
    "            df.loc[sorted_indices, pop_col] += int(diff / abs(diff))\n",
    "    return df\n",
    "\n",
    "\n",
    "def ipf_adjustment(df, row_control_totals, col_control_totals, age_cols, max_iterations=10, tol=1e-6):\n",
    "    for _ in range(max_iterations):\n",
    "        \n",
    "        # We do col total matching last here, because we are interested, at 10km in the best age DISTRIBUTION, not exact matching total.\n",
    "        row_totals = df[age_cols].sum(axis=1)\n",
    "        scaling_factors = row_control_totals / row_totals\n",
    "        # Set inf to 1\n",
    "        scaling_factors[~np.isfinite(scaling_factors)] = 1\n",
    "        df[age_cols] = df[age_cols].multiply(scaling_factors, axis=0)\n",
    "\n",
    "        col_totals = df[age_cols].sum()\n",
    "        scaling_factors = col_control_totals / col_totals\n",
    "        # Set inf to 1\n",
    "        scaling_factors[~np.isfinite(scaling_factors)] = 1\n",
    "        df[age_cols] = df[age_cols].multiply(scaling_factors, axis=1)\n",
    "        print(df[age_cols].sum().sum())\n",
    "        error = 1\n",
    "        if error < tol:\n",
    "            break\n",
    "    return df\n",
    "\n",
    "\n",
    "def mix_age_distribution(df, age_cols, total_col, reference_distribution, threshold=150):\n",
    "    cell_count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        pop = row[total_col]\n",
    "        if threshold > pop > 0:\n",
    "            cell_count += 1\n",
    "            weight = pop / threshold\n",
    "            adjusted_values = weight * row[age_cols] + (1 - weight) * reference_distribution * pop\n",
    "            df.loc[index, age_cols] = adjusted_values  #/ adjusted_values.sum() * pop\n",
    "    print(f\"Adjusted {cell_count} cells.\")\n",
    "    print(f\"Total cells: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load preprocessed data\n",
    "#one_km_df = pd.read_csv(\"3adjusted_1km_with_higher.csv\")\n",
    "#hundred_m_df = pd.read_csv(\"3adjusted_100m_with_higher.csv\")\n",
    "ten_km_df = pd.read_csv(r\"C:\\Users\\petre\\Documents\\GitHub\\MATSimPipeline\\data\\syn_pop\\merged_10km_gitter.csv\")\n",
    "\n",
    "# Adjust the 10km level using IPF and mix age distribution\n",
    "print(\"Adjusting age distribution at the 10km level...\")\n",
    "age_cols_10km_10er = [\n",
    "    # 10er-Gruppen\n",
    "    'Unter10_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a10bis19_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a20bis29_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a30bis39_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a40bis49_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a50bis59_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a60bis69_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a70bis79_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a80undaelter_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter']\n",
    "\n",
    "age_cols_10km_5er = [\n",
    "    # 5er-Gruppen\n",
    "    'Unter18_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter',\n",
    "    'a18bis29_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter',\n",
    "    'a30bis49_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter',\n",
    "    'a50bis64_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter',\n",
    "    'a65undaelter_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'\n",
    "]\n",
    "# Count nans\n",
    "nans = ten_km_df[age_cols_10km_10er+age_cols_10km_5er].isna().sum().sum()\n",
    "print(f\"Total nans: {nans}\")\n",
    "# Set nans in given cols to 0\n",
    "ten_km_df[age_cols_10km_10er+age_cols_10km_5er] = ten_km_df[age_cols_10km_10er+age_cols_10km_5er].fillna(0)\n",
    "print(\"Nans set to 0.\")\n",
    "\n",
    "reference_distribution_10km_10er = ten_km_df[age_cols_10km_10er].sum() / ten_km_df[age_cols_10km_10er].sum().sum()\n",
    "reference_distribution_10km_5er = ten_km_df[age_cols_10km_5er].sum() / ten_km_df[age_cols_10km_5er].sum().sum()\n",
    "col_totals_10er = ten_km_df[age_cols_10km_10er].sum().copy()\n",
    "col_totals_5er = ten_km_df[age_cols_10km_5er].sum().copy()\n",
    "row_totals_10er = ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter'].copy()\n",
    "row_totals_5er = ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'].copy()\n",
    "print(f\"Diff in totals (should be 0): {row_totals_10er.sum() - row_totals_5er.sum()}\")\n",
    "ten_km_df = mix_age_distribution(ten_km_df, age_cols_10km_10er,\n",
    "                                 'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "                                 reference_distribution_10km_10er)\n",
    "ten_km_df = mix_age_distribution(ten_km_df, age_cols_10km_5er,\n",
    "                                 \"Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter\",\n",
    "                                 reference_distribution_10km_5er)\n",
    "ten_km_df = ipf_adjustment(ten_km_df, row_totals_10er, col_totals_10er, age_cols_10km_10er)\n",
    "ten_km_df = ipf_adjustment(ten_km_df, row_totals_5er, col_totals_5er, age_cols_10km_5er)\n",
    "ten_km_df.to_csv(\"3_4adjusted_10km_ipf.csv\", index=False)\n",
    "\n",
    "# Do NOT integerize\n",
    "# Save\n",
    "print(\"Saved adjusted 10km IPF results to 3_4adjusted_10km_ipf.csv\")\n",
    "print(\"Col totals differ a tiny bit between 10er and 5er groups, but that's ok and left that way so we keep the best possible distribution.\"\n",
    "      \"The total population is the same for both groups, and the row totals match exactly.\")\n"
   ],
   "id": "4be58c098fa05f24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting age distribution at the 10km level...\n",
      "Total nans: 208\n",
      "Nans set to 0.\n",
      "Diff in totals (should be 0: 0.0\n",
      "Adjusted 52 cells.\n",
      "Total cells: 3824\n",
      "Adjusted 52 cells.\n",
      "Total cells: 3824\n",
      "82711150.0\n",
      "82711150.0\n",
      "82711150.0\n",
      "82711150.0\n",
      "82711150.0\n",
      "82711150.0\n",
      "82711150.0\n",
      "82711150.0\n",
      "82711150.0\n",
      "82711150.0\n",
      "82710877.0\n",
      "82710877.0\n",
      "82710877.0\n",
      "82710877.0\n",
      "82710877.0\n",
      "82710877.0\n",
      "82710877.0\n",
      "82710877.0\n",
      "82710877.0\n",
      "82710877.0\n",
      "Saved adjusted 10km IPF results to 3_4adjusted_10km_ipf.csv\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T14:57:13.440789500Z",
     "start_time": "2025-03-24T10:36:52.966566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "adj_df = pd.read_csv(\"3_4adjusted_10km_ipf.csv\")\n",
    "orig_df = pd.read_csv(r\"C:\\Users\\petre\\Documents\\GitHub\\MATSimPipeline\\data\\syn_pop\\merged_10km_gitter.csv\")\n",
    "\n",
    "diff_df = adj_df[age_cols_10km_10er+age_cols_10km_5er] - orig_df[age_cols_10km_10er+age_cols_10km_5er]\n",
    "print(diff_df.abs().max())\n",
    "\n",
    "# Zeige jeweils das maximum der Col an\n",
    "print(orig_df[age_cols_10km_10er+age_cols_10km_5er].max())\n",
    "\n",
    "# Print the diffs between row totals (should be 0) the diffs between col totals (can be a slight diff) and the diff betw row and col totals for each grouping\n",
    "print(f\"Row total diff 10er/5er: {adj_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter'].sum() - adj_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'].sum()}\")\n",
    "print(f\"Col total diff 10er/5er: {adj_df[age_cols_10km_10er].sum().sum() - adj_df[age_cols_10km_5er].sum().sum()}\")\n",
    "print(f\"Row v Col total diff 10er: {adj_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter'].sum() - adj_df[age_cols_10km_10er].sum().sum()}\")\n",
    "print(f\"Row v Col total diff 5er: {adj_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'].sum() - adj_df[age_cols_10km_5er].sum().sum()}\")\n"
   ],
   "id": "22fe8c2d9635f81c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unter10_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter         3.566970\n",
      "a10bis19_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        4.596714\n",
      "a20bis29_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        6.695852\n",
      "a30bis39_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        2.985058\n",
      "a40bis49_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        4.232525\n",
      "a50bis59_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        7.174324\n",
      "a60bis69_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        8.726717\n",
      "a70bis79_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        6.543100\n",
      "a80undaelter_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter    3.583652\n",
      "Unter18_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter            4.886568\n",
      "a18bis29_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter           8.151290\n",
      "a30bis49_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter           6.287109\n",
      "a50bis64_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter           7.563742\n",
      "a65undaelter_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter       8.791690\n",
      "dtype: float64\n",
      "Unter10_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter          97485.0\n",
      "a10bis19_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter         77860.0\n",
      "a20bis29_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        128501.0\n",
      "a30bis39_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        199688.0\n",
      "a40bis49_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        143363.0\n",
      "a50bis59_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter        123404.0\n",
      "a60bis69_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter         81868.0\n",
      "a70bis79_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter         53670.0\n",
      "a80undaelter_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter     46554.0\n",
      "Unter18_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter            161426.0\n",
      "a18bis29_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter           142418.0\n",
      "a30bis49_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter           343053.0\n",
      "a50bis64_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter           170061.0\n",
      "a65undaelter_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter       133970.0\n",
      "dtype: float64\n",
      "Row total diff 10er/5er: 0.0\n",
      "Col total diff 10er/5er: 273.0\n",
      "Row v Col total diff 10er: 232.0\n",
      "Row v Col total diff 5er: 505.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T15:16:22.904453Z",
     "start_time": "2025-03-27T14:55:17.897627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We now have good age distros for all 10km cells.\n",
    "# Now, for 1km and 100km, mix age distributions for low pop cells downward from higher level, then do IPF\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def smart_integerize(df, pop_cols):\n",
    "    for pop_col in pop_cols:\n",
    "        total_before = df[pop_col].sum()\n",
    "        df[pop_col] = df[pop_col].round().astype(int)\n",
    "        total_after = df[pop_col].sum()\n",
    "        diff = total_before - total_after\n",
    "        if diff != 0:\n",
    "            sorted_indices = df[pop_col].abs().sort_values(ascending=False).index[:abs(int(diff))]\n",
    "            df.loc[sorted_indices, pop_col] += int(diff / abs(diff))\n",
    "    return df\n",
    "\n",
    "\n",
    "def ipf_adjustment(df, row_control_totals, col_control_totals, relevant_cols, max_iterations=10, tol=1e-6):\n",
    "    for _ in range(max_iterations):\n",
    "\n",
    "    # Here we do rows last, so the population total per cell is hit exactly\n",
    "\n",
    "        col_totals = df[relevant_cols].sum()\n",
    "        scaling_factors = col_control_totals / col_totals\n",
    "        # Set inf to 1\n",
    "        scaling_factors[~np.isfinite(scaling_factors)] = 1\n",
    "        df[relevant_cols] = df[relevant_cols].multiply(scaling_factors, axis=1)\n",
    "    \n",
    "        row_totals = df[relevant_cols].sum(axis=1)\n",
    "        scaling_factors = row_control_totals / row_totals\n",
    "        # Set inf to 1\n",
    "        scaling_factors[~np.isfinite(scaling_factors)] = 1\n",
    "        df[relevant_cols] = df[relevant_cols].multiply(scaling_factors, axis=0)\n",
    "\n",
    "        error = 1\n",
    "        if error < tol:\n",
    "            break\n",
    "    return df\n",
    "\n",
    "\n",
    "def mix_distributions(df, age_cols, total_col, reference_cols, threshold=100):\n",
    "    mask = (df[total_col] > 0) & (df[total_col] < threshold)\n",
    "    cell_count = mask.sum()\n",
    "\n",
    "    if cell_count == 0:\n",
    "        print(\"No cells adjusted.\")\n",
    "        return df\n",
    "\n",
    "    weight = df.loc[mask, total_col] / threshold\n",
    "    weight = weight.values.reshape(-1, 1)\n",
    "\n",
    "    pop = df.loc[mask, total_col].values.reshape(-1, 1)\n",
    "    age_data = df.loc[mask, age_cols].values\n",
    "    # Fit age data\n",
    "    age_data = age_data / age_data.sum(axis=1).reshape(-1, 1) * pop  # scale age data to pop\n",
    "    #age_data = np.nan_to_num(age_data)\n",
    "    ref_data = df.loc[mask, reference_cols].values * pop  # scale reference by pop\n",
    "\n",
    "    adjusted = weight * age_data + (1 - weight) * ref_data\n",
    "    df.loc[mask, age_cols] = adjusted\n",
    "\n",
    "    adjusted_row_sums = df.loc[mask, age_cols].sum(axis=1)\n",
    "    print(f\"Row sums mixing: {adjusted_row_sums.sum()}\")\n",
    "    print(f\"Total pop: {df.loc[mask, total_col].sum()}\")\n",
    "    #assert np.allclose(adjusted_row_sums, df.loc[mask, total_col], atol=1e-3), \"Row sums do not match total pop.\"\n",
    "    \n",
    "    print(f\"Adjusted {cell_count} cells.\")\n",
    "    print(f\"Total cells: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load preprocessed data\n",
    "one_km_df = pd.read_csv(\"3adjusted_1km_with_higher.csv\")\n",
    "hundred_m_df = pd.read_csv(\"3adjusted_100m_with_higher.csv\")\n",
    "ten_km_df = pd.read_csv(\"3_4adjusted_10km_ipf.csv\")\n",
    "\n",
    "age_cols_10km_10er = [\n",
    "    # 10er-Gruppen\n",
    "    'Unter10_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a10bis19_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a20bis29_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a30bis39_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a40bis49_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a50bis59_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a60bis69_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a70bis79_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter',\n",
    "    'a80undaelter_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter']\n",
    "\n",
    "age_cols_10km_5er = [\n",
    "    # 5er-Gruppen\n",
    "    'Unter18_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter',\n",
    "    'a18bis29_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter',\n",
    "    'a30bis49_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter',\n",
    "    'a50bis64_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter',\n",
    "    'a65undaelter_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'\n",
    "]\n",
    "\n",
    "# 1km level\n",
    "print(\"Adjusting age distribution at the 1km level...\")\n",
    "\n",
    "age_cols_1km_5er = [col.replace('10km', '1km') for col in age_cols_10km_5er]\n",
    "age_cols_1km_10er = [col.replace('10km', '1km') for col in age_cols_10km_10er]\n",
    "# Count nans\n",
    "nans = one_km_df[age_cols_1km_10er+age_cols_1km_5er].isna().sum().sum()\n",
    "print(f\"Total nans: {nans}\")\n",
    "# Set nans in given cols to 0.00001 (to avoid div by 0)\n",
    "one_km_df[age_cols_1km_10er+age_cols_1km_5er] = one_km_df[age_cols_1km_10er+age_cols_1km_5er].fillna(0.00001)\n",
    "print(\"Nans set to 0.00001.\")\n",
    "\n",
    "ten_km_df['age_sum_10er'] = ten_km_df[age_cols_10km_10er].sum(axis=1) # Minimal!! anders als die \"Insgesamt\" Reihensumme (nur bei 10km!), deswegen so\n",
    "ten_km_df['age_sum_5er'] = ten_km_df[age_cols_10km_5er].sum(axis=1)\n",
    "\n",
    "for col in age_cols_10km_10er:\n",
    "    ten_km_df[f'{col}_prop'] = ten_km_df[col] / ten_km_df['age_sum_10er']\n",
    "for col in age_cols_10km_5er:\n",
    "    ten_km_df[f'{col}_prop'] = ten_km_df[col] / ten_km_df['age_sum_5er']\n",
    "\n",
    "age_prop_cols_10er = [f'{col}_prop' for col in age_cols_10km_10er]\n",
    "age_prop_cols_5er = [f'{col}_prop' for col in age_cols_10km_5er]\n",
    "\n",
    "one_km_df = one_km_df.merge(ten_km_df[['GITTER_ID_10km'] + age_prop_cols_5er + age_prop_cols_10er],\n",
    "                            on='GITTER_ID_10km', how='left')\n",
    "\n",
    "assert one_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter'].sum() == one_km_df[\n",
    "    'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter'].sum()\n",
    "\n",
    "# We now have the relative distributions of the 10km cells in the 1km cells. Now they are mixed where needed.\n",
    "one_km_df = mix_distributions(one_km_df, age_cols_1km_10er,\n",
    "                                 'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter', age_prop_cols_10er)\n",
    "one_km_df = mix_distributions(one_km_df, age_cols_1km_5er,\n",
    "                                    'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter', age_prop_cols_5er)\n",
    "\n",
    "# Per-cell IPF: We have mixed distributions per 1km cell. To make sure the 1km cell distros also in sum match the 10km cells, AND\n",
    "# the population totals per cell are still met (which they already are but adjusting distro messes with them) we do IPF, but per 10km cell.\n",
    "\n",
    "grouped_1km = one_km_df.groupby('GITTER_ID_10km')\n",
    "debug_counter = 0\n",
    "for gid, group in tqdm(grouped_1km):\n",
    "    debug_counter += 1\n",
    "    # Only ipf \n",
    "    row_control_totals_10er = group['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter'].values.copy()\n",
    "    # Get col totals from 10km cell\n",
    "    col_control_totals_10er = ten_km_df.loc[ten_km_df['GITTER_ID_10km'] == gid, age_cols_10km_10er].values[0].copy()\n",
    "    relevant_cols = age_cols_1km_10er\n",
    "    group = ipf_adjustment(group, row_control_totals_10er, col_control_totals_10er, relevant_cols)\n",
    "    one_km_df.loc[group.index, relevant_cols] = group[relevant_cols]\n",
    "\n",
    "    row_control_totals_5er = group['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter'].values[0].copy()\n",
    "    # Get col totals from 10km cell\n",
    "    col_control_totals_5er = ten_km_df.loc[ten_km_df['GITTER_ID_10km'] == gid, age_cols_10km_5er].values[0].copy()\n",
    "    relevant_cols = age_cols_1km_5er\n",
    "    group = ipf_adjustment(group, row_control_totals_5er, col_control_totals_5er, relevant_cols)\n",
    "    one_km_df.loc[group.index, relevant_cols] = group[relevant_cols]\n",
    "    if debug_counter > 20:\n",
    "        break\n",
    "    \n",
    "# As result, we have the robust distros from more aggregated cells, but localized data mixed in. \n",
    "# NO integerization\n",
    "\n",
    "# Save only top 100 rows\n",
    "#one_km_df.head(100).to_csv(\"4adjusted_1km_mixing_ipf.csv\", index=False)\n",
    "\n",
    "one_km_df.to_csv(\"4adjusted_1km_mixing_ipf.csv\", index=False)\n",
    "print(\"Saved adjusted 1km IPF results to 4adjusted_1km_mixing_ipf.csv\")\n",
    "\n",
    "# Short check that the totals were not messed up (we don't edit them here but just to be sure)\n",
    "print(\"Totals (should match):\")\n",
    "print(one_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter'].sum())\n",
    "print(one_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter'].sum())\n",
    "print(ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter'].sum())\n",
    "print(ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'].sum())\n",
    "\n",
    "totals_diffs = (ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter'].values -\n",
    "                one_km_df.groupby('GITTER_ID_10km')['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter'].sum().values)\n",
    "print(max(totals_diffs))\n",
    "totals_diffs = (ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'].values -\n",
    "                one_km_df.groupby('GITTER_ID_10km')['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter'].sum().values)\n",
    "print(max(totals_diffs))\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# 100m level with integerization\n",
    "print(\"Adjusting age distribution at the 100m level...\")\n",
    "age_cols_100m_5er = [\n",
    "    # 5er-Gruppen\n",
    "    'Unter18_Zensus2022_Alter_5Altersklassen_100m-Gitter',\n",
    "    'a18bis29_Zensus2022_Alter_5Altersklassen_100m-Gitter',\n",
    "    'a30bis49_Zensus2022_Alter_5Altersklassen_100m-Gitter',\n",
    "    'a50bis64_Zensus2022_Alter_5Altersklassen_100m-Gitter',\n",
    "    'a65undaelter_Zensus2022_Alter_5Altersklassen_100m-Gitter'\n",
    "]\n",
    "# age_cols_1km_5er = [\n",
    "#     # 5er-Gruppen\n",
    "#     'Unter18_Zensus2022_Alter_5Altersklassen_1km-Gitter',\n",
    "#     'a18bis29_Zensus2022_Alter_5Altersklassen_1km-Gitter',\n",
    "#     'a30bis49_Zensus2022_Alter_5Altersklassen_1km-Gitter',\n",
    "#     'a50bis64_Zensus2022_Alter_5Altersklassen_1km-Gitter',\n",
    "#     'a65undaelter_Zensus2022_Alter_5Altersklassen_1km-Gitter'\n",
    "# ]\n",
    "#age_cols_100m_5er = [col.replace('10km', '100m') for col in age_cols_10km_5er]\n",
    "age_cols_100m_10er = [col.replace('10km', '100m') for col in age_cols_10km_10er]\n",
    "# Count nans\n",
    "nans = hundred_m_df[age_cols_100m_5er+age_cols_100m_10er].isna().sum().sum()\n",
    "print(f\"Total nans: {nans}\")\n",
    "# Set nans in given cols to 0\n",
    "hundred_m_df[age_cols_100m_5er+age_cols_100m_10er] = hundred_m_df[age_cols_100m_5er+age_cols_100m_10er].fillna(0.00001)\n",
    "print(\"Nans set to 0.00001.\")\n",
    "\n",
    "#TODO: IPF is broken thus the prop cols dont add up to 1 and make 100m bad too\n",
    "for col in age_cols_1km_10er:\n",
    "    one_km_df[f'{col}_prop'] = one_km_df[col] / one_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter']\n",
    "for col in age_cols_1km_5er:\n",
    "    one_km_df[f'{col}_prop'] = one_km_df[col] / one_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter']\n",
    "age_prop_cols_10er = [f'{col}_prop' for col in age_cols_1km_10er]\n",
    "age_prop_cols_5er = [f'{col}_prop' for col in age_cols_1km_5er]\n",
    "\n",
    "hundred_m_df = hundred_m_df.merge(one_km_df[['GITTER_ID_1km'] + age_prop_cols_5er + age_prop_cols_10er],\n",
    "                            on='GITTER_ID_1km', how='left')\n",
    "\n",
    "assert hundred_m_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_100m-Gitter'].sum() == hundred_m_df[\n",
    "    'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_100m-Gitter'].sum()\n",
    "\n",
    "# We now have the relative distributions of the 1km cells in the 100m cells. Now they are mixed where needed (which is almost always at this level)\n",
    "\n",
    "#age_cols_100m_10er = [col.replace('10km', '1km') for col in age_cols_10km_10er]\n",
    "#age_cols_1km_5er = [col.replace('10km', '1km') for col in age_cols_10km_5er]\n",
    "\n",
    "hundred_m_df = mix_distributions(hundred_m_df, age_cols_100m_10er,\n",
    "                                 'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_100m-Gitter', age_prop_cols_10er)\n",
    "hundred_m_df = mix_distributions(hundred_m_df, age_cols_100m_5er,\n",
    "                                    'Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_100m-Gitter', age_prop_cols_5er)\n",
    "\n",
    "\n",
    "# Per-cell IPF: We have mixed distributions per 1km cell. To make sure the 1km cell distros also in sum match the 10km cells, AND\n",
    "# the population totals per cell are still met (which they already are but adjusting distro messes with them) we do IPF, but per 10km cell.\n",
    "\n",
    "grouped_100m = hundred_m_df.groupby('GITTER_ID_1km')\n",
    "debug_counter = 0\n",
    "for gid, group in tqdm(grouped_100m):\n",
    "    debug_counter += 1\n",
    "    row_control_totals_10er = group['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_100m-Gitter'].values[0].copy()\n",
    "    # Get col totals from 1km cell\n",
    "    col_control_totals_10er = one_km_df.loc[one_km_df['GITTER_ID_1km'] == gid, age_cols_1km_10er].values[0].copy()\n",
    "    relevant_cols = age_cols_100m_10er\n",
    "    group = ipf_adjustment(group, row_control_totals_10er, col_control_totals_10er, relevant_cols)\n",
    "    hundred_m_df.loc[group.index, relevant_cols] = group[relevant_cols]\n",
    "\n",
    "    row_control_totals_5er = group['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_100m-Gitter'].values[0].copy()\n",
    "    # Get col totals from 1km cell\n",
    "    col_control_totals_5er = one_km_df.loc[one_km_df['GITTER_ID_1km'] == gid, age_cols_1km_5er].values[0].copy()\n",
    "    relevant_cols = age_cols_100m_5er\n",
    "    group = ipf_adjustment(group, row_control_totals_5er, col_control_totals_5er, relevant_cols)\n",
    "    hundred_m_df.loc[group.index, relevant_cols] = group[relevant_cols]\n",
    "    if debug_counter > 20:\n",
    "        break\n",
    "    \n",
    "# As result, we have the robust distros from more aggregated cells, but localized data mixed in. \n",
    "# # Integerize (not for now while debugging)\n",
    "hundred_m_df.to_csv(\"4adjusted_100m_mixing_ipf.csv\", index=False)\n",
    "print(\"Saved adjusted 1km IPF results to 4adjusted_1km_mixing_ipf.csv\")\n"
   ],
   "id": "43700bf72c2f0dc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_1568\\466555968.py:77: DtypeWarning: Columns (34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  one_km_df = pd.read_csv(\"3adjusted_1km_with_higher.csv\")\n",
      "C:\\Users\\petre\\AppData\\Local\\Temp\\ipykernel_1568\\466555968.py:78: DtypeWarning: Columns (27,34,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  hundred_m_df = pd.read_csv(\"3adjusted_100m_with_higher.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting age distribution at the 1km level...\n",
      "Total nans: 719488\n",
      "Nans set to 0.00001.\n",
      "Row sums mixing: 3676946.0\n",
      "Total pop: 3676946\n",
      "Adjusted 122315 cells.\n",
      "Total cells: 212746\n",
      "Row sums mixing: 3676946.0\n",
      "Total pop: 3676946\n",
      "Adjusted 122315 cells.\n",
      "Total cells: 212746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/3824 [00:11<36:35,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved adjusted 1km IPF results to 4adjusted_1km_mixing_ipf.csv\n",
      "Totals (should match):\n",
      "82711381\n",
      "82711381\n",
      "82711382.0\n",
      "82711382.0\n",
      "18.0\n",
      "18.0\n",
      "Adjusting age distribution at the 100m level...\n",
      "Total nans: 21842251\n",
      "Nans set to 0.00001.\n",
      "Row sums mixing: 62775848.737544045\n",
      "Total pop: 62778168\n",
      "Adjusted 2963028 cells.\n",
      "Total cells: 3147936\n",
      "Row sums mixing: 62728384.679754764\n",
      "Total pop: 62778168\n",
      "Adjusted 2963028 cells.\n",
      "Total cells: 3147936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating: thread_id: pid_1568_id_2080410978448\n",
      "frame_id: 2080753941104\n",
      "scope: FRAME\n",
      "attrs: hundred_m_df\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\JetBrains\\PyCharm 2024.1.2\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_resolver.py\", line 178, in _getPyDictionary\n",
      "    attr = getattr(var, n)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\miniforge3\\envs\\MATSimPipeline\\Lib\\site-packages\\pandas\\core\\frame.py\", line 3978, in T\n",
      "    return self.transpose()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\miniforge3\\envs\\MATSimPipeline\\Lib\\site-packages\\pandas\\core\\frame.py\", line 3937, in transpose\n",
      "    new_arr = self.values.T\n",
      "              ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\miniforge3\\envs\\MATSimPipeline\\Lib\\site-packages\\pandas\\core\\frame.py\", line 12664, in values\n",
      "    return self._mgr.as_array()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\miniforge3\\envs\\MATSimPipeline\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1694, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\miniforge3\\envs\\MATSimPipeline\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1734, in _interleave\n",
      "    rl = blk.mgr_locs\n",
      "         ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\miniforge3\\envs\\MATSimPipeline\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 266, in mgr_locs\n",
      "    @property\n",
      "    \n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\JetBrains\\PyCharm 2024.1.2\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_vars.py\", line 315, in resolve_compound_variable_fields\n",
      "    return _typeName, _resolve_default_variable_fields(var, resolver, offset)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\JetBrains\\PyCharm 2024.1.2\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_vars.py\", line 265, in _resolve_default_variable_fields\n",
      "    return resolver.get_dictionary(VariableWithOffset(var, offset) if offset else var)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\JetBrains\\PyCharm 2024.1.2\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_resolver.py\", line 86, in get_dictionary\n",
      "    return self._getPyDictionary(var, names)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\petre\\AppData\\Local\\JetBrains\\PyCharm 2024.1.2\\plugins\\python-ce\\helpers\\pydev\\_pydevd_bundle\\pydevd_resolver.py\", line 191, in _getPyDictionary\n",
      "    strIO = StringIO.StringIO()\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  0%|          | 20/211473 [00:48<141:35:49,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved adjusted 1km IPF results to 4adjusted_1km_mixing_ipf.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " # Check results\n",
    "one_km_df = pd.read_csv(\"4adjusted_1km_mixing_ipf.csv\")\n",
    "ten_km_df = pd.read_csv(\"3_4adjusted_10km_ipf.csv\")\n",
    "hundred_m_df = pd.read_csv(\"4adjusted_100m_ipf.csv\")\n",
    "\n",
    "# Short check that the totals were not messed up (we don't edit them here but just to be sure)\n",
    "print(\"Totals (should match):\")\n",
    "print(one_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter'].sum())\n",
    "print(one_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter'].sum())\n",
    "print(ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter'].sum())\n",
    "print(ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'].sum())\n",
    "\n",
    "totals_diffs = (ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_10km-Gitter'].values -\n",
    "                one_km_df.groupby('GITTER_ID_10km')['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_10er-Jahresgruppen_1km-Gitter'].sum().valus())\n",
    "print(max(totals_diffs))\n",
    "totals_diffs = (ten_km_df['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_10km-Gitter'].values -\n",
    "                one_km_df.groupby('GITTER_ID_10km')['Insgesamt_Bevoelkerung_Zensus2022_Alter_in_5_Altersklassen_1km-Gitter'].sum().values)\n",
    "print(max(totals_diffs))\n",
    "\n",
    "# Compare total distros\n",
    "distro_diffs = (ten_km_df[age_cols_10km_10er].sum() - one_km_df[age_cols_1km_10er].sum()).abs()\n",
    "print(distro_diffs.max())\n",
    "distro_diffs = (ten_km_df[age_cols_10km_5er].sum() - one_km_df[age_cols_1km_5er].sum()).abs()\n",
    "print(distro_diffs.max())\n",
    "distro_diffs = (one_km_df[age_cols_1km_10er].sum() - hundred_m_df[age_cols_100m_10er].sum()).abs()\n",
    "print(distro_diffs.max())\n",
    "distro_diffs = (one_km_df[age_cols_1km_5er].sum() - hundred_m_df[age_cols_100m_5er].sum()).abs()\n",
    "print(distro_diffs.max())\n",
    "\n",
    "# Compare per-cell distros\n",
    "\n",
    "\n"
   ],
   "id": "240bd978429d8771"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
